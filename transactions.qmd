---
pagetitle: "`r paste('Transactions Report', Sys.Date())`"
format: 
  html:
    page-layout: full
    embed-resources: true
toc: true
toc-expand: true
execute:
  echo: false
  warning: false
theme:
  - pulse
html-table-processing: none
engine: knitr
---

{{< include header.qmd >}}

# Title goes here

Hello there.

```{r}
#| label: globals
source(file.path("R", "functions.R"))

TRANSACTIONS_PATH_RAW <- "data/raw/current-acc-trans.csv"
TRANSACTIONS_PATH_CLEAN <- "data/clean/current-acc-trans.csv"
ACCOUNTS_PATH_RAW <- "data/raw/accounts.csv"
ACCOUNTS_PATH_CLEAN <- "data/clean/accounts.csv"
```

```{r}
#| label: clean-accounts-csv
#| output: false

# Cleaning up the accounts dataset.
# The cleaning is minimal - I have only done what is required for the tasks.

# During initial EDA of the `account_type` col I saw there were both
# `current` and `current+` account types. I wondered if the plus symbol was a
# typo, but there are 6,688 and 1,366 of each, respectively. This seems like
# too many `current+` to be an accident, so I didn't clean and combine the two
# groups.

# The regex below removes all whitespace (\s) and non-word (\W) chars from
# `title`, so that e.g. `Mr.` becomes `Mr`. Otherwise they appear as two
# separate categories.

# There's also a rogue single space in the `account_type` column.
# I decided to clean that at read-time by setting `nullstr`.

ddbExecute(
  "
  COPY (
    SELECT *
      REPLACE (
        title.regexp_replace('\\s|\\W', '', 'g').lower() AS title,
        account_type.trim().lower() AS account_type
      )
      FROM read_csv(?, nullstr = [' ', ''])
  ) TO ?;
  ",
  from_path = ACCOUNTS_PATH_RAW,
  to_path = ACCOUNTS_PATH_CLEAN
)
```

```{r}
#| label: titles

# 1. Count the number of account holders with each title

n_titles <- ddbGetQuery(
  "
  SELECT title as Title, COUNT(*) as Count
  FROM ?
  GROUP BY title
  ORDER By Count DESC;
  ",
  from = ACCOUNTS_PATH_CLEAN
)

n_titles
```

```{r}
#| label: title-vs-account-type

# 2. Produce a cross-table showing the number of account holders broken down by title and
# account_type (i.e. a count of the number of people with each combination of possible account types and titles)

title_vs_account_type <- ddbGetQuery(
  "
  SELECT title as Title,
         account_type as 'Account Type',
         count(*) as Count
  FROM ?
  WHERE account_type IS NOT NULL
  GROUP BY ALL
  ORDER BY ALL;
  ",
  from = ACCOUNTS_PATH_CLEAN
)

title_vs_account_type
```

```{r}
#| label: avg-overdraft-limit-by-title-and-account-type

# 3. Produce a cross-table showing the average overdraft_limit by title and account_type

# Assuming that "average" is the mean
avg_overdraft_limits <- ddbGetQuery(
  "
  SELECT title as Title,
         account_type as 'Account Type',
         avg(overdraft_limit) as 'Average Overdraft Limit'
  FROM ?
  WHERE account_type IS NOT NULL
  GROUP BY ALL
  ORDER BY ALL;
  ",
  from = ACCOUNTS_PATH_CLEAN
)

avg_overdraft_limits
```

```{r}
#| label: overdraft-sum-by-title-and-account-type

# 4. Produce a cross-table showing the aggregate overdraft_limit (sum of) by
# Â title and account_type

overdrafts_summed <- ddbGetQuery(
  "
  SELECT title as Title,
         account_type as 'Account Type',
         sum(overdraft_limit) as 'Overdraft Limit Sum'
  FROM ?
  WHERE account_type IS NOT NULL
  GROUP BY ALL
  ORDER BY ALL;
  ",
  from = ACCOUNTS_PATH_CLEAN
)

overdrafts_summed
```

```{r}
#| label: transactions-per-customer

# 5. For each customer count the number of transactions in the transaction data
# and compute the total value of those transactions for each customer

# There are 10,000 account numbers in accounts.csv
# And 64,498 unique account numbers in the transaction data
# I'm guessing that the people in accounts.csv are our customers. We want to
# filter down the transaction data to only include them.

# To get the unique counts of accounts
# ddbGetQuery("select count(distinct account_number) from 'data/clean/accounts.csv';")
# ddbGetQuery("select count(distinct acc_number) from 'data/clean/current-acc-trans.csv';")

# Due diligence: number of unique `transaction_ids` is equal to the transaction
# dataset's nrow
# ddbGetQuery("select count(distinct trans_id) from 'data/clean/current-acc-trans.csv';")
# ddbGetQuery("select count(*) from 'data/clean/current-acc-trans.csv';")

# Using a semi join here. It's a kind of filtering join. The left table gets
# filtered down to only include matches from the right table.
transactions_per_customer <- ddbGetQuery(
  "
  SELECT acc_number as 'Account Number',
         count(*) as 'Transactions (Count)',
         sum(amount) as 'Total Value'
  FROM ? t
  SEMI JOIN ? a
         ON t.acc_number = a.account_number
  GROUP BY t.acc_number
  ORDER BY 'Transactions (Count)';
  ",
  t = TRANSACTIONS_PATH_CLEAN,
  a = ACCOUNTS_PATH_CLEAN
) |>
  dplyr::arrange(dplyr::desc(`Transactions (Count)`))

# A few accounts have huge number of transactions, e.g. 11336875 has 693
# Took a look - seems fine. Though they seem to be up at all hours of the day!
# dplyr::arrange(
#   ddbGetQuery(
#     "select *
#         from 'data/clean//current-acc-trans.csv'
#         where acc_number = '11336875';"
#   ),
#   trans_date
# )

summary(transactions_per_customer)
```